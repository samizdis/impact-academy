
\section{Dataset}\label{app:dataset}
We describe the \benchmark{} dataset in more detail, providing a breakdown of question categories in \benchmark{} (\cref{app:dataset-breakdown}) and describing additional and considerations for \benchmark{}-Bio (\cref{app:dataset-bio} and \benchmark{}-Chem (\cref{app:dataset-chem}). Then, we outline the unlearning corpora for \benchmark{} (\cref{app:bio_corpora,app:cyber_corpora}).
\subsection{Dataset Breakdown}\label{app:dataset-breakdown}
\input{tables/dataset_size}
\vspace{16pt}

\subsection{Additional Considerations for \benchmark{}-Bio}\label{app:dataset-bio}
The questions generated based on our threat model in \cref{subsec:dataset-bio} primarily test for \textit{knowledge} on how to develop or use pre-existing resources acquire bioweapons, including some types of tacit knowledge, such as the knowledge needed to troubleshooting experiments in a laboratory. While a common objection to this method may be that other critical parts of the bioweapons acquisition pathway (such as acquiring reagents or equipment) represent the ``true'' bottleneck, we believe testing for knowledge is still useful for several reasons: first, it is unclear to what extent pre-existing bottlenecks in reagent and equipment acquisition will remain in the future, due to accelerating progress in laboratory automation, outsourcing, and science democratization (such as with the proliferation so-called ``citizen science'' or ``biohacker'' labs). Second, certain types of knowledge can accelerate risks by unblocking bottlenecks around equipment and reagents (such as knowledge of DNA synthesis screening vulnerabilities). Finally, to a first approximation, knowledge of more dangerous threats can still increase the marginal risk profile of the expected economic damage and casualties from bioweapons development, despite additional bottlenecks in the larger bioweapons acquisition pathway. 


\subsection{Additional Considerations for \benchmark{}-Chem}\label{app:dataset-chem}
Careful consideration of the full process by which malicious actors will access and deploy chemical weapons and/or explosives has led us to define the following categories of knowledge to include in \benchmark{}-Chem:
\begin{itemize}
    \item General knowledge, which refers to fundamental scientific knowledge of the target materials and their properties;
    \item Synthesis, which refers to all preparation procedures, including chemical syntheses and other fabrication procedures;
    \item Sourcing/procurement, which refers to knowledge about how to access starting materials, particularly in ways that are outside of established and regulated chemistry laboratories;
    \item Purification, which refers to knowledge about how to purify crude products after they are successfully synthesized, particularly using methods that work outside of a regulated laboratory;
    \item Analysis/verification, which refers to the procedures required to analyze all target compounds, as well as the intermediates accessed as part of the synthetic pathway. Such procedures are necessary to confirm that the desired compounds have been synthesized, and are of sufficiently high purity to ensure that their usage will have the desired effect.
    \item Deployment mechanisms (e.g. device, plans), which refers to all knowledge necessary to effectively deploy the chemical weapons and/or explosive, including fabrication of a device; dispersal of the compound in an aerosol, capsule, or vapor form; dissolution of the compound in the drinking water supply; and diffusion of the compound into the HVAC system of a target location.
    \item Deployment: bypassing detection, which refers to all technical knowledge that is necessary to avoid detection by law enforcement authorities. This includes knowledge about how to transport materials through the mass transportation network, how to use covert methods to access all necessary materials, and how to deploy the compound in a way that limits the individualâ€™s potential exposure to liability.
    \item Miscellaneous knowledge, which refers to all additional knowledge that is not covered in the aforementioned categories, including knowledge about derivation of target chemical weapons and/or explosives, properties of such derivatives, and information about mitigation and response strategies that people are likely to use following the deployment of the harmful agents.
\end{itemize}

\subsection{Bio Corpora}\label{app:bio_corpora}
The forget and retain corpora are a collection of papers from PubMed. The forget set includes papers that were used to generate the \benchmark{}-Bio questions, while the retain set samples papers across categories for general biology, while omitting papers in the forget set and using keyword exclusion against the topics in our biosecurity questions.

\subsection{Cyber Corpora}\label{app:cyber_corpora}
The forget and retain corpora consist of passages scraped via keyword search on GitHub. The keywords used for the forget corpora are 
\begin{lstlisting}
fuzzing
how to fuzz
fuzzing tutorial
binary exploitation
exploit mitigation bypass
hardware exploitation
clock glitching
voltage glitching
firmware extraction
cyber operations
red team
dynamic analysis
firewall bypass
offensive operations
data exfiltration
network sniffing
evading detection
network tunneling
service enumeration
voltage glitching
JTAG
offensive reconnaissance
\end{lstlisting}

We then employ \textsc{Mixtral-8x7B-Instruct-v0.1}~\citep{jiang2024mixtral} to filter the dataset further with the following prompt, accepting passages only with a score of 9 or higher:
\begin{lstlisting}
You will be presented with pieces of text about computer security. Your task is to analyze each text and determine whether the text is about offensive cybersecurity and hacking procedures in the areas of {desired_topics_string}. Please provide a JSON response containing the `reasoning' and a `rating'. Just respond with raw valid JSON starting with {{ and do not put it in a code block or include any other text. `reasoning' should include the thought process that helps you come to a decision. `rating' should be a single number from 0-10, where 0 represents "no technical content related to offensive cybersecurity practices" and 10 means "very detailed technical content related to offensive cybersecurity practices". Intermediate texts that do not clearly fall into either category should be rated accordingly.

A piece of text is considered to be related to offensive cybersecurity and hacking procedures if it contains procedural knowledge, details or code which would allow a user to perform offensive operations using tools from {desired_topics_string}. The text should contain enough technical details and provide clear instructions on how to perform offensive practices.

A piece of text is considered to be not related to offensive cybersecurity and hacking procedures if it contains information, licenses, textbooks, resources, or code about offensive cybersecurity practices, but does not contain by itself enough clear and technical details to perform offensive operations.
\end{lstlisting}

For the retain set, we use the following search terms:
\begin{lstlisting}
data structures
databases
computer architecture
operating systems
web development
systems programming
\end{lstlisting}






